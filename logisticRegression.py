# -*- coding: utf-8 -*-
"""
Created on Sat Jul 27 18:20:44 2019

@author: feeling
"""
'''  
import matplotlib.pyplot as plt
from sklearn import linear_model
import numpy as np
from sklearn.linear_model import LinearRegression  # 导入线性回归模型
from sklearn.preprocessing import PolynomialFeatures  # 导入多项式回归模型
from sklearn.externals import joblib


plt.figure()  # 实例化作图变量
plt.title('aming trans line points')  # 图像标题
plt.xlabel('aming point')  # x轴文本
plt.ylabel('aming value')  # y轴文本
# ####plt.axis([30, 400, 100, 400])
plt.grid(True)  # 是否绘制网格线

# 训练数据（给定的阿明转化指数x和阿明转化后数据y）
# X = [[49960], [44917], [37668], [34094], [32014], [30942], [29053], [27020], [26990], [25664], [23603], [23398],
#      [23367], [23098], [22903], [22445], [21491], [21436]]
# y = [[116104], [96288], [70703], [59376], [53187], [50114], [44893], [39557], [39479], [36163], [31259], [30788],
#      [30716], [30105], [29665], [28640], [26558], [26440]]

# X = [[121],[500],[1000],[2000],[3000],[4000],[4500],[5000],[5500],[6000],[6500],[7000],[8000],[9000],[10000],[11000],[12000],[13000],[14000],[15000],[16000],[16095],[17000],[18000],[20000],[22000],[25000],[27000],[30000]]
#
# y = [[6],[51],[154],[475],[930],[1503],[1832],[2187],[2568],[2975],[3407],[3864],[4850],[5929],[7099],[8359],[9705],[11137],[12653],[14252],[15931],[16095],[17691],[19531],[23443],[27661],[34548],[39505],[47478]]

# X = [[24],[30],[45],[51],[63],[68],[73],[100],[110],[120],[130],[140],[150],[160],[170],[180],[190],[200],[250],[300]]
# y = [[1],[2],[3],[4],[5],[6],[7],[12],[14],[17],[20],[22],[25],[29],[32],[36],[40],[44],[69],[99]]


X = [[100238],[100684],[103151],[124110],[135088],[142819],[160868],[164034],[201110],[238193],[268577]]

y = [[397760],[400913],[418531],[581628],[676460],[747052],[923886],[956623],[1377408],[1865567],[2314307]]

#X = [[1000],[1200],[1500],[1700],[1800],[1900],[2000],[2200],[2500],[3000],[3500],[4000],[4500],[5000],[5500],[6000],[6500],[7000],[8000],[9000],[10000],[11000],[12000],[13000],[14000],[15000],[16000],[16095],[17000],[18000],[20000],[22000],[25000],[27000],[30000]]
#y = [[154],[207],[297],[364],[400],[437],[475],[556],[687],[930],[1202],[1503],[1832],[2187],[2568],[2975],[3407],[3864],[4850],[5929],[7099],[8359],[9705],[11137],[12653],[14252],[15931],[16095],[17691],[19531],[23443],[27661],[34548],[39505],[47478]]

# 做最终效果预测的样本
X_test = X  # 用来做最终效果测试
y_test = y  # 用来做最终效果测试

# 绘制散点图
plt.scatter(X, y, marker='*', color='blue', label='阿明指数转化样本')

# 线性回归
model = LinearRegression()
model.fit(X, y)
# 模型拟合效果得分
print('一元线性回归 r-squared', model.score(X_test, y_test))
x2 = [[21436], [49960]]  # 所绘制直线的横坐标x的起点和终点
y2 = model.predict(x2)
################plt.plot(x2, y2, 'g-')  # 绿色的直线

# 二次多项式回归
# 实例化一个二次多项式特征实例
quadratic_featurizer = PolynomialFeatures(degree=3)
# 用二次多项式对样本X值做变换
X_train_quadratic = quadratic_featurizer.fit_transform(X)
# 创建一个线性回归实例
regressor_model = linear_model.LinearRegression()
# 以多项式变换后的x值为输入，带入线性回归模型做训练
regressor_model.fit(X_train_quadratic, y)
# 设计x轴一系列点作为画图的x点集  起始点，最大值，多少个点
xx = np.linspace(1000, 30000, 1000)
# 把训练好X值的多项式特征实例应用到一系列点上,形成矩阵
xx_quadratic = quadratic_featurizer.transform(xx.reshape(xx.shape[0], 1))
yy_predict = regressor_model.predict(xx_quadratic)
# 用训练好的模型作图
plt.plot(xx, yy_predict, 'r-')
X_test_quadratic = quadratic_featurizer.transform(X_test)
print('二次回归  r-squared', regressor_model.score(X_test_quadratic, y_test))

# 三次多项式回归
cubic_featurizer = PolynomialFeatures(degree=3)
X_train_cubic = cubic_featurizer.fit_transform(X)
regressor_cubic = LinearRegression()
regressor_cubic.fit(X_train_cubic, y)
xx_cubic = cubic_featurizer.transform(xx.reshape(xx.shape[0], 1))
plt.plot(xx, regressor_cubic.predict(xx_cubic))
X_test_cubic = cubic_featurizer.transform(X_test)
print('三次回归     r-squared', regressor_cubic.score(X_test_cubic, y_test))
plt.show()  # 展示图像

# 保存模型
# joblib.dump(regressor_cubic, './model/modelFile.pkl')
joblib.dump(regressor_cubic, './modelFile_8.pkl')

# 加载模型(--加载)
clf3 = joblib.load('./modelFile_8.pkl')
# 使用模型预测检测准确度
print('使用模型预测准确度:', regressor_cubic.score(X_test_cubic, y_test))
# 使用模型预测计算
##(--加载)
# cubic_featurizer = PolynomialFeatures(degree=3)
##(--加载)
# X_train_cubic2 = cubic_featurizer.fit_transform(X)
##(--加载)
# X_test_cubic2 = cubic_featurizer.transform(X_test)
##(--加载)
# print('使用模型预测计算值:',clf3.predict(X_test_cubic2))
'''


from sklearn.preprocessing import PolynomialFeatures  # 导入多项式回归模型
from sklearn.externals import joblib
clf3 = joblib.load('./modelFile_8.pkl')
#     # 使用模型预测计算
#     ##(--加载)
cubic_featurizer = PolynomialFeatures(degree=3)
#     ##(--加载)
X_train_cubic2 = cubic_featurizer.fit_transform([[142819]])
#     ##(--加载)
X_test_cubic2 = cubic_featurizer.transform([[142819]])
#     ##(--加载)
print('使用模型预测计算值:',clf3.predict(X_test_cubic2))















'''

训练数据
107---2300
X = [[121],[171],[288],[533],[640],[713],[1006],[1228],[1505],[1998],[2258],[2525],[2982]]
y = [[6],[10],[22],[57],[76],[90],[156],[215],[299],[475],[581],[699],[921]]

对应模型  modelFile_1.pkl

2300-10400
X = [[2307],[2421],[3071],[3469],[3499],[3774],[3851],[3931],[3987],[4066],[4073],[4263],[4330],[4707],[5414],[5527],[5527],[5582],[5593],[5752],[5813],[6169],[6549],[7061],[7453],[7465],[7529],[7708],[7776],[8286],[8390],[8490],[9730],[9830]]

y = [[602],[652],[967],[1185],[1202],[1364],[1411],[1460],[1495],[1545],[1550],[1673],[1717],[1976],[2501],[2590],[2590],[2634],[2643],[2771],[2821],[3119],[3452],[3922],[4299],[4312],[4374],[4553],[4621],[5149],[5260],[5368],[6775],[6895]
]

对应模型   modelFile_2.pkl

10400—22000

X = [[10401],[10747],[11043],[11491],[11538],[13312],[14015],[14460],[15487],[15871],[16817],[17039],[17138],[17279],[17875],[18088],[18095],[19868],[20064],[20786],[20797],[21434],[22980]]

y = [[7594],[8032],[8416],[9010],[9073],[11602],[12677],[13378],[15060],[15710],[17364],[17762],[17941],[18196],[19297],[19696],[19710],[23175],[23574],[25064],[25087],[26436],[29839]]

对应模型   modelFile_3.pkl

22000—46600
X = [[21645],[25461],[26198],[27047],[27402],[28395],[28844],[29209],[30801],[31189],[31696],[32113],[35041],[41775],[43499],[44820]]

y = [[26891],[35666],[37482],[39625],[40536],[43134],[44330],[45315],[49715],[50815],[52266],[53476],[62295],[84774],[91014],[95924]]
对应模型   modelFile_4.pkl


46600—59900

X = [[47025],[47613],[47636],[47636],[49205],[51265],[51397],[52936],[52992],[53394],[53591],[55770],[56573],[59525]]

y = [[104373],[106680],[106768],[106768],[113035],[121495],[122047],[128556],[128794],[130521],[131369],[140927],[144524],[158091]]
对应模型   modelFile_5.pkl


59900—70600
[60021],[60651],[61128],[61507],[62043],[62673],[63260],[66068],[67594],[69849]
[160419],[163404],[165677],[167496],[170083],[173141],[176018],[190051],[197876],[209697]

对应模型   modelFile_6.pkl

70600—98500
X = [[72104],[74550],[75620],[80453],[81280],[82772],[82772],[82926],[82989],[83065],[85952],[88770],[94508],[97439]]

y = [[221816],[235300],[241314],[269288],[274216],[283198],[283198],[284128],[284514],[284974],[302764],[320593],[358281],[378246]]


对应模型   modelFile_7.pkl


98500—122300


X = [[100238],[100684],[103151],[124110],[135088],[142819],[160868],[164034],[201110],[238193],[268577]]

y = [[397760],[400913],[418531],[581628],[676460],[747052],[923886],[956623],[1377408],[1865567],[2314307]]


对应模型   modelFile_8.pkl

'''




























